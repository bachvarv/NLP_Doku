\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\providecommand \oddpage@label [2]{}
\babel@aux{ngerman}{}
\babel@aux{ngerman}{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Einleitung und Problemstellung}{1}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@input{chapters/Word2Vec.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Glove}{5}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The GloVe Method}{5}{section.3.1}\protected@file@percent }
\newlabel{x_i}{{3.1}{5}{The GloVe Method}{equation.3.1.1}{}}
\newlabel{p_ij}{{3.2}{5}{The GloVe Method}{equation.3.1.2}{}}
\newlabel{tab_1}{{\caption@xref {tab_1}{ on input line 23}}{6}{The GloVe Method}{table.caption.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Tabelle von dem Vorkommen der beiden Wörter \textit  {ice} und \textit  {steam}\relax }}{6}{table.caption.10}\protected@file@percent }
\newlabel{ice_steam_tab}{{3.1}{6}{Tabelle von dem Vorkommen der beiden Wörter \textit {ice} und \textit {steam}\relax }{table.caption.10}{}}
\newlabel{alg_f}{{3.3}{6}{The GloVe Method}{equation.3.1.3}{}}
\newlabel{f_dif}{{3.4}{6}{The GloVe Method}{equation.3.1.4}{}}
\newlabel{f_dot}{{3.5}{6}{The GloVe Method}{equation.3.1.5}{}}
\newlabel{f_hom}{{3.6}{7}{The GloVe Method}{equation.3.1.6}{}}
\newlabel{f_hom_res}{{3.7}{7}{The GloVe Method}{equation.3.1.7}{}}
\newlabel{f_hom_sol}{{3.8}{7}{The GloVe Method}{equation.3.1.8}{}}
\newlabel{f_simp}{{3.9}{7}{The GloVe Method}{equation.3.1.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Der Transformer}{8}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{Transformer}{{4}{8}{Der Transformer}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Struktur des Transformers}{8}{section.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Das Transformer-Modell\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{transformer}{{4.1}{8}{Das Transformer-Modell\relax }{figure.caption.11}{}}
\citation{denis_Transformer:02}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Positionale Einbettung}{9}{subsection.4.1.1}\protected@file@percent }
\citation{denis_Transformer:02}
\citation{denis_Transformer:02}
\citation{denis_Transformer:02}
\citation{denis_Transformer:02}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Encoder und Decoder}{10}{subsection.4.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Multi-Head-Attention Layer}{10}{section*.12}\protected@file@percent }
\citation{denis_Transformer:02}
\citation{denis_Transformer:02}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Heads \cite  {denis_Transformer:02}\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{multi_head}{{4.2}{11}{Heads \cite {denis_Transformer:02}\relax }{figure.caption.13}{}}
\citation{Vaswani:2017}
\@writefile{toc}{\contentsline {subsubsection}{Feed Forward Network}{12}{section*.14}\protected@file@percent }
\citation{transformer_tensorflow:21}
\@writefile{toc}{\contentsline {subsubsection}{Masked Multi-Head Attention Layer}{13}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Implementierung}{13}{section.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Die Klasse}{13}{section*.16}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.1}Definition des Transformers}{13}{lstlisting.4.1}\protected@file@percent }
\citation{Vaswani:2017}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.2}Hyperparameter}{14}{lstlisting.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Encoder}{14}{section*.17}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {4.3}Encoder}{14}{lstlisting.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Decoder}{14}{section*.18}\protected@file@percent }
\citation{BERT:19}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}BERT}{15}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Struktur des BERTs}{15}{section.5.1}\protected@file@percent }
\citation{BERT:19}
\citation{BERT:19}
\citation{wikitext2:20}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Implentierung}{16}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Pre-Training a BERT-Model}{16}{subsection.5.2.1}\protected@file@percent }
\citation{d2l:21}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}Erstellen von Eingabe und Klasse}{17}{subsection.5.2.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}Nutzung der Dive into Deep Learning (d2l) Bibliothek}{17}{lstlisting.5.1}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}Erstellen der Trainingsdaten für NSP}{17}{lstlisting.5.2}\protected@file@percent }
\citation{BERT:19}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.3}Erstellen von Trainingsdaten für MLM}{18}{lstlisting.5.3}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.4}Eingabedaten}{18}{lstlisting.5.4}\protected@file@percent }
\citation{BERT:19}
\@writefile{toc}{\contentsline {subsubsection}{BERT Class}{19}{section*.19}\protected@file@percent }
\newlabel{bert_class}{{5.2.2}{19}{BERT Class}{section*.19}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.5}Die Hyperparametern vom BERT}{19}{lstlisting.5.5}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.6}BERT-Struktur bei Pre-Training}{19}{lstlisting.5.6}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.7}Definition des BERT-Encoder-Layers}{19}{lstlisting.5.7}\protected@file@percent }
\citation{BERT:19}
\citation{BERT:19}
\citation{CO:19}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces BERT Eingabeschicht \cite  {BERT:19}\relax }}{20}{figure.caption.20}\protected@file@percent }
\newlabel{embl}{{5.1}{20}{BERT Eingabeschicht \cite {BERT:19}\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsubsection}{Optimizer und Loss-Funktion}{20}{section*.21}\protected@file@percent }
\newlabel{optimizer_and_loss}{{5.2.2}{20}{Optimizer und Loss-Funktion}{section*.21}{}}
\citation{tfhub:21}
\citation{BERTMM:21}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Fine-Tuning a BERT-Model}{21}{subsection.5.2.3}\protected@file@percent }
\newlabel{fine_tuning}{{5.2.3}{21}{Fine-Tuning a BERT-Model}{subsection.5.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{BERT-Model}{21}{section*.22}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.8}Laden von dem BERT-Model}{21}{lstlisting.5.8}\protected@file@percent }
\newlabel{BERT_Definition}{{5.9}{22}{Definition des BERT-Models zur Anpassung}{lstlisting.5.9}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.9}Definition des BERT-Models zur Anpassung}{22}{lstlisting.5.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Datensatz}{22}{section*.23}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.10}Laden der Trainingsdaten}{23}{lstlisting.5.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Optimizer und Fehlerfunktion}{23}{section*.24}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.11}BERT Optimizer}{23}{lstlisting.5.11}\protected@file@percent }
\@input{chapters/Visualization.aux}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Zusammenfassung und Ausblick}{28}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\bibstyle{geralpha}
\bibdata{literatur}
\bibcite{d2l:21}{AS}
\bibcite{BERTMM:21}{Hub21a}
\bibcite{tfhub:21}{Hub21b}
\bibcite{BERT:19}{JDT19}
\bibcite{wikitext2:20}{Mer}
\bibcite{denis_Transformer:02}{Rot00}
\bibcite{Vaswani:2017}{Vas17}
\bibcite{transformer_tensorflow:21}{Web21}
\bibcite{CO:19}{Wie21}
\@writefile{toc}{\contentsline {chapter}{Literaturverzeichnis}{29}{chapter*.30}\protected@file@percent }
\@input{chapters/Glossar.aux}
\@input{chapters/Selbststaendigkeitserklaerung.aux}
\gdef \@abspage@last{35}

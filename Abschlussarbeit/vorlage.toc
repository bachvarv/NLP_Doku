\babel@toc {ngerman}{}
\babel@toc {ngerman}{}
\contentsline {chapter}{\numberline {1}Einleitung und Problemstellung}{1}{chapter.1}%
\contentsline {chapter}{\numberline {2}Word2Vec}{2}{chapter.2}%
\contentsline {section}{\numberline {2.1}Word Embedding}{2}{section.2.1}%
\contentsline {subsubsection}{SKIP-gram Model}{3}{section*.6}%
\contentsline {subsubsection}{CBOW Model}{4}{section*.8}%
\contentsline {subsection}{\numberline {2.1.1}Implementierung}{4}{subsection.2.1.1}%
\contentsline {chapter}{\numberline {3}Glove}{5}{chapter.3}%
\contentsline {section}{\numberline {3.1}The GloVe Method}{5}{section.3.1}%
\contentsline {chapter}{\numberline {4}Der Transformer}{8}{chapter.4}%
\contentsline {section}{\numberline {4.1}Struktur des Transformers}{8}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Positionale Einbettung}{9}{subsection.4.1.1}%
\contentsline {subsection}{\numberline {4.1.2}Encoder und Decoder}{10}{subsection.4.1.2}%
\contentsline {subsubsection}{Multi-Head-Attention Layer}{10}{section*.12}%
\contentsline {subsubsection}{Feed Forward Network}{12}{section*.14}%
\contentsline {subsubsection}{Masked Multi-Head Attention Layer}{13}{section*.15}%
\contentsline {section}{\numberline {4.2}Implementierung}{13}{section.4.2}%
\contentsline {subsubsection}{Die Klasse}{13}{section*.16}%
\contentsline {subsubsection}{Encoder}{14}{section*.17}%
\contentsline {subsubsection}{Decoder}{14}{section*.18}%
\contentsline {chapter}{\numberline {5}BERT}{16}{chapter.5}%
\contentsline {section}{\numberline {5.1}Struktur des BERTs}{16}{section.5.1}%
\contentsline {section}{\numberline {5.2}Implentierung}{17}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Pre-Training a BERT-Model}{17}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Erstellen von Eingabe und Klasse}{18}{subsection.5.2.2}%
\contentsline {subsubsection}{BERT Class}{20}{section*.19}%
\contentsline {subsubsection}{Optimizer und Loss-Funktion}{21}{section*.21}%
\contentsline {subsection}{\numberline {5.2.3}Fine-Tuning a BERT-Model}{22}{subsection.5.2.3}%
\contentsline {subsubsection}{BERT-Model}{22}{section*.22}%
\contentsline {subsubsection}{Datensatz}{23}{section*.23}%
\contentsline {subsubsection}{Optimizer und Fehlerfunktion}{24}{section*.24}%
\contentsline {chapter}{\numberline {6}BERT-Basierte Modelle}{25}{chapter.6}%
\contentsline {section}{\numberline {6.1}Neural Machine Translation Model}{25}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Struktur des NMT-Model}{25}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}Implementierung}{26}{subsection.6.1.2}%
\contentsline {chapter}{\numberline {7}Vektordarstellung}{27}{chapter.7}%
\contentsline {section}{\numberline {7.1}Einleitung}{27}{section.7.1}%
\contentsline {section}{\numberline {7.2}Prozess}{27}{section.7.2}%
\contentsline {subsubsection}{1. Schritt: Standardization}{27}{section*.26}%
\contentsline {subsubsection}{2. Schritt: Berechnung der Kovarianzmatrix}{28}{section*.27}%
\contentsline {subsubsection}{3. Berechnung der Eigenvektors und Eigenwerte}{28}{section*.28}%
\contentsline {subsubsection}{4. Transformation der Daten}{30}{section*.30}%
\contentsline {chapter}{\numberline {8}Zusammenfassung und Ausblick}{31}{chapter.8}%
\contentsline {chapter}{Literaturverzeichnis}{32}{chapter*.31}%
\contentsline {chapter}{Glossar}{33}{appendix.A}%
\contentsline {chapter}{Erklärung der Kandidatin / des Kandidaten}{34}{appendix.B}%

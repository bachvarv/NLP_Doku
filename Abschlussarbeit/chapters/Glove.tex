\chapter{GloVe}

Die Idee von \textbf{Glo}bal \textbf{Ve}ctors ist es, den Sinn hinter einem Wort in numerischer Vektorform darzustellen. GloVe ist eine weitere Möglichkeit neben word2vec(\cref{word2vec}) wie man Wörter oder sogar ganze Texte als Vektoren repräsentiert.

\section{GloVe-Methode}
Einige Variablen werden zuerst eingeleitet. Die Matrix der Word-Word-co-occu-rrence wird mit \textbf{$X$} notiert und eine beliebige Komponente in der Matrix mit \textbf{$X_{ij}$}. Der Wert \textbf{$X_{ij}$} stellt dar, wie oft das Wort \textit{j} in dem Kontext vom Wort \textit{i} vorkommt. Weiterhin beschreibt die Einheit \textbf{$X_i$} die Anzahl des Vorkommens eines beliebigen Wortes in dem Kontext vom Wort \textit{i} und ist in der folgenden \cref{x_i} definiert:

\begin{equation}
	X_i = \sum_{k} X_{ik}. \cite{GloVe:14}
	\label{x_i}
\end{equation}

Schließlich definieren wir die Einheit \textbf{$P_{ij}$}, die beschreibt, wie hoch die Wahrscheinlichkeit ist, dass ein Wort \textit{j} in dem Kontext vom Wort \textit{i} vorkommt. Die Formel ist in der \cref{p_ij} aufgeführt:

\begin{equation}
	P_{ij} = P(j|i) = \frac{X_{ij}}{X_i}. \cite{GloVe:14}
	\label{p_ij}
\end{equation}

Ein kleines Beispiel wird angegeben, damit verstanden werden kann, wie bestimmte Aspekte aus dem gemeinsamen Auftreten von Wörtern gewonnen werden können. Es werden zwei Wörter \textit{i} und \textit{j} betrachtet, die in einem Corpus vorkommen. Das Beispiel stammt aus dem Artikel \cite{GloVe:14} und ist aus dem Themenbereich des thermodynamischen Zustands. Nehmen wir die Wörter \textit{$i = ice$} und \textit{$j = steam$}. Die Beziehung der beiden Wörter kann so untersucht werden, indem die Relation mit anderen Probewörtern \textit{k} berechnet wird. Für Wörter, die in direktem Bezug zu \textit{$i = ice$} stehen, erwarten wir, dass das Verhältnis $\frac{P_{ik}}{P_{jk}}$ groß ist, zum Beispiel wenn das Wort \textit{$k = solid$} gewählt wird. Analoge Beziehung kann bei Wörtern betrachtet werden, die näher an Bedeutung zu \textit{$j = steam$} stehen. In solchen Fällen werden wir einen kleineren Wert des Bruchs $\frac{P_{ik}}{P_{jk}}$ erhalten - zum Beispiel wählen wir das Wort \textit{$k = gas$}. Selbstverständlich ist der Wert des Bruchs gleich eins, wenn das Wort \textit{k} zu beiden Wörtern \textit{i, j} in Korrelation steht, oder wenn sich keine Korrelation ergibt. Als Beispiel können wir das Wort \textit{$k = sun$} wählen. Die \cref{ice_steam_tab} stellt das Verhältnis zwischen den Wörtern dar:

	\begin{table}[]\label{tab_1}
		\centering
		\begin{tabular}{l|l|l|l|l}
			Probability and Ration & k = solid                                           & k = gas                                             & k = water                                           & k = fashion                                         \\ \hline
			P(k|ice)               & 1.9\times 10^{-4} & 6.6\times 10^{-5} & 3.0\times 10^{-3} & 1.7\times 10^{-5} \\
			P(k|steam)             & 2.2\times 10^{-5} & 7.8\times 10^{-4} & 2.2\times 10^{-3} & 1.8\times 10^{-5} \\
			P(k|ice)/P(k|steam)    & 8.9                                                 & 8.5\times 10^{-2} & 1.36                                                & 0.96                                               
		\end{tabular}
		\captionof{table}{Tabelle von dem Vorkommen der beiden Wörter \textit{ice} und \textit{steam} \cite{GloVe:14}}\label{ice_steam_tab}
	\end{table}
 
Die Erwartungen werden durch die \cref{ice_steam_tab} gerechtfertigt. Die Rate erlaubt uns, die Verhältnisse zwischen den einzelnen Wörtern besser zu verstehen. Mit Hilfe des Bruches wird unterschieden, wie die Wörter zueinander stehen, im Gegensatz zu der einfachen Wahrscheinlichkeit.

Zu betrachten ist, dass die Wahrscheinlichkeit der Koinzidenz von drei Eingangsgrößen \textit{i}, \textit{j}, \textit{k}, abhängt. Die Allgemeinform der Funktion ist in der \cref{alg_f} angegeben:

\begin{equation}
	F(w_i, w_j, \~w_k) = \frac{P_{ik}}{P_{jk}} \cite{GloVe:14}.
	\label{alg_f}
\end{equation}

Die Wortvektoren für untersuchte Wörter \textit{i,j} sind durch \textit{w} $\in$ $\mathbb{R^d}$ gegeben und das betrachtete Wort {k} ist mit Vektor \textit{\~w} $\in$ $\mathbb{R^d}$ repräsentiert. In der Gleichung entsteht die rechte Seite aus dem Corpus (Vocabulary). F hängt in diesem Fall von den drei Vektoren $w_i, w_j, \~w_k$ ab. F wird im nächsten Schritt wegen der hohen Variation der Formel angepasst. Zuerst ist es gewünscht, die Information aus der Rate in Word-Vector-Raum darzustellen. Da Vektorräume ursprünglich linear sind, kann dies in einer Vektordifferenz erfolgen. Somit fällt der Fokus nur auf die Funktionen, die von der Differenz der zwei Vektoren abhängen. Die Änderung wird aus der \cref{f_dif} ersichtlich.

\begin{equation}
F((w_i - w_j), \~w_k) = \frac{P_{ik}}{P_{jk}} \cite{GloVe:14}.
\label{f_dif}
\end{equation}

Für die Gleichung ist es zu erwähnen, dass die Parameter von F Vektoren sind, während die rechte Seite ein Skalar ist. Während \textit{F} als eine komplexere Funktion, die von einem neuronalen Netz parametrisiert werden kann, genommen werden kann, würde das die Linearstruktur der Formel verschleiern. Es wird das Skalarprodukt genommen, damit die Verschleierung vermieden wird. Die \cref{f_dot} stellt die Änderung dar.
\begin{equation}
F((w_i - w_j)^T\~w_k) = \frac{P_{ik}}{P_{jk}} \cite{GloVe:14}.
\label{f_dot}
\end{equation}

Laut \cite{GloVe:14} erfolgt in der word-word Koinzidenzmatrizen der Unterschied zwischen Wort und Kontextwort willkürlich. Die Formel für F muss erlauben, dass zwei Rollen beliebig ausgetauscht werden können. Das heißt also nicht nur $w \leftrightarrow \~w$ auszutauschen, sondern auch $X \leftrightarrow X^T$. Um diese Symmetrie zu verschaffen, sind zwei einfache Schritte erforderlich. Zuerst muss sichergestellt werden, dass die Formel homomorphisch zwischen den Gruppen ($\mathbb{R}$, +) und ($\mathbb{R}_{>0}$, $\times$) ist:

\begin{equation}
F((w_i - w_j)^T\~w_k) = \frac{F(w_i^T\~w_k)}{F(w_j^T\~w_k)} \cite{GloVe:14},
\label{f_hom}
\end{equation}	

was nach \cref{f_dot} wie folgt aussieht:

\begin{equation}
F(w_i^T\~w_k) = P_{ik} =\frac{X_{ik}}{X_i} \cite{GloVe:14}.
\label{f_hom_res}
\end{equation}

Die Lösung von \cref{f_hom} ist $F = exp$, oder auch:

\begin{equation}
w_i^T\~w_k = \log (P_{ik}) = \log(X_{ik}) - \log(X_i) \cite{GloVe:14}.
\label{f_hom_sol}
\end{equation}

Zunächst wird die Gleichung umgestellt, jedoch werden einige Konstanten eingeführt. Es könnte der Wert von $\log(X_i)$ in einer Konstante $b_i$ umgewandelt werden. Schließlich wird die Konstante $b_k$ addiert, damit die Symmetrie erhalten wird. Die vereinfachte Formel ist in der \cref{f_simp} gegeben:

\begin{equation}
w_i^T\~w_k + b_i + \~b_k = \log(X_{ik}) \cite{GloVe:14}.
\label{f_simp}
\end{equation}

Nach der Einführung in Wortvektoren steigen wir in den nächsten Kapiteln ins Hauptthema Transformer ein. Die Folgekapitel erläutern die Struktur und Implementierung von dem Transformer und \textbf{B}idirectional \textbf{E}ncoder \textbf{R}epresentation from \textbf{T}ransformer (oder kurz BERT). Schließlich wird ein Modell vorgestellt, das versucht die Hauptaufgabe dieser Ausarbeitung zu lösen.

